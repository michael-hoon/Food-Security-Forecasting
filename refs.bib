@article{
doi:10.1126/science.1185383,
author = {H. Charles J. Godfray  and John R. Beddington  and Ian R. Crute  and Lawrence Haddad  and David Lawrence  and James F. Muir  and Jules Pretty  and Sherman Robinson  and Sandy M. Thomas  and Camilla Toulmin },
title = {Food Security: The Challenge of Feeding 9 Billion People},
journal = {Science},
volume = {327},
number = {5967},
pages = {812-818},
year = {2010},
doi = {10.1126/science.1185383},
URL = {https://www.science.org/doi/abs/10.1126/science.1185383},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1185383},
abstract = {Continuing population and consumption growth will mean that the global demand for food will increase for at least another 40 years. Growing competition for land, water, and energy, in addition to the overexploitation of fisheries, will affect our ability to produce food, as will the urgent requirement to reduce the impact of the food system on the environment. The effects of climate change are a further threat. But the world can produce more food and can ensure that it is used more efficiently and equitably. A multifaceted and linked global strategy is needed to ensure sustainable and equitable food security, different components of which are explored here.}}
@misc{unsdg2,
  author       = {{United Nations}},
  title        = {Goal 2: Zero Hunger},
  year         = {2023},
  url          = {https://www.un.org/sustainabledevelopment/hunger/},
  note         = {Retrieved from: \url{https://www.un.org/sustainabledevelopment/hunger/}}
}
@article{GaussMarkov,
 ISSN = {00031305},
 URL = {http://www.jstor.org/stable/2684451},
 abstract = {In the standard linear regression model with independent, homoscedastic errors, the Gauss-Markov theorem asserts that Î²Ì‚, = (X'X)-1(X'y) is the best linear unbiased estimator of Î² and, furthermore, that c'Î²Ì‚ is the best linear unbiased estimator of c'Î² for all p Ã— 1 vectors c. In the corresponding random regressor model, X is a random sample of size n from a p-variate distribution. If attention is restricted to linear estimators of c'Î² that are conditionally unbiased, given X, the Gauss-Markov theorem applies. If, however, the estimator is required only to be unconditionally unbiased, the Gauss-Markov theorem may or may not hold, depending on what is known about the distribution of X. The results generalize to the case in which X is a random sample without replacement from a finite population.},
 author = {Juliet Popper Shaffer},
 journal = {The American Statistician},
 number = {4},
 pages = {269--273},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {The Gauss-Markov Theorem and Random Regressors},
 urldate = {2023-11-17},
 volume = {45},
 year = {1991}
}

@article{MeanImputation,
author = {Anil Jadhav, Dhanya Pramod and Krishnan Ramanathan},
title = {Comparison of Performance of Data Imputation Methods for Numeric Dataset},
journal = {Applied Artificial Intelligence},
volume = {33},
number = {10},
pages = {913-933},
year = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/08839514.2019.1637138},
URL = {https://doi.org/10.1080/08839514.2019.1637138},
eprint = {https://doi.org/10.1080/08839514.2019.1637138}
}

@book{Greene2003Econometric,
  added-at = {2018-06-18T21:23:34.000+0200},
  author = {Greene, William H.},
  biburl = {https://www.bibsonomy.org/bibtex/28ded70f02507563c15bfdd8dd2208e12/pbett},
  citeulike-article-id = {14358797},
  citeulike-attachment-1 = {Greene_EconometricAnalysis_5thEd_2002.pdf; /pdf/user/pbett/article/14358797/1109751/Greene_EconometricAnalysis_5thEd_2002.pdf; 555dcbdff6a834feae11ed60d48b3ca8f6e3c5b3},
  citeulike-linkout-0 = {http://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm},
  comment = {(private-note)Used as the reference for the statsmodels python package for prediction intervals - see p111.},
  edition = {Fifth},
  file = {Greene_EconometricAnalysis_5thEd_2002.pdf},
  interhash = {fb74ec9471c97eb32162f303c71262e1},
  intrahash = {8ded70f02507563c15bfdd8dd2208e12},
  isbn = {0-13-066189-9},
  keywords = {textbook statistics economics},
  posted-at = {2017-05-17 18:18:23},
  priority = {2},
  publisher = {Pearson Education},
  timestamp = {2018-06-22T18:36:55.000+0200},
  title = {Econometric Analysis},
  url = {http://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm},
  year = 2003
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}


@inbook{adjsutedrsquared,
author = {Miles, Jeremy},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118445112},
title = {R Squared, Adjusted R Squared},
booktitle = {Wiley StatsRef: Statistics Reference Online},
chapter = {},
pages = {},
doi = {https://doi.org/10.1002/9781118445112.stat06627},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06627},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118445112.stat06627},
year = {2014},
keywords = {ANOVA, least squares, proportion of variance, regression},
abstract = {Abstract R-squared and adjusted R-squared are statistics derived from analyses based on the general linear model (e.g., regression, ANOVA). It represents the proportion of variance in the outcome variable which is explained by the predictor variables in the sample (R-squared) and an estimate in the population (adjusted R-squared).}
}

@book{James2013,
  added-at = {2019-10-12T20:03:56.000+0200},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  biburl = {https://www.bibsonomy.org/bibtex/2444186c86d18bddb4433c12fa126f6be/lopusz_kdd},
  interhash = {b3febabdc45a8629023cee7323dfbd86},
  intrahash = {444186c86d18bddb4433c12fa126f6be},
  keywords = {general_machine_learning},
  publisher = {Springer},
  timestamp = {2019-10-12T23:45:37.000+0200},
  title = {An Introduction to Statistical Learning: with Applications in R },
  url = {https://faculty.marshall.usc.edu/gareth-james/ISL/},
  year = 2013
}

@article{AICBIC,
 ISSN = {00129658, 19399170},
 URL = {http://www.jstor.org/stable/43495189},
 author = {Ken Aho and DeWayne Derryberry and Teri Peterson},
 journal = {Ecology},
 number = {3},
 pages = {631--636},
 publisher = {Wiley},
 title = {Model selection for ecologists: the worldviews of AIC and BIC},
 urldate = {2023-11-21},
 volume = {95},
 year = {2014}
}

@incollection{heteroskedasticity,
    author = {Pesaran, M. Hashem},
    isbn = {9780198736912},
    title = "{83Heteroskedasticity}",
    booktitle = "{Time Series and Panel Data Econometrics}",
    publisher = {Oxford University Press},
    year = {2015},
    month = {10},
    abstract = "{This chapter extends the important extension of the classical model, introduced in Chapter 2, by allowing the disturbances to have variances that differ across different cross section units, namely to be heteroskedastic. The discussions cover regression models with heteroskedastic disturbances; an efficient estimation of the regression coefficients in the presence of heteroskedasticity; general models of heteroskedasticity; and diagnostic checks and tests of homoskedasticity. Exercises are provided at the end of the chapter.}",
    doi = {10.1093/acprof:oso/9780198736912.003.0004},
    url = {https://doi.org/10.1093/acprof:oso/9780198736912.003.0004},
    eprint = {https://academic.oup.com/book/0/chapter/364200282/chapter-pdf/44352583/acprof-9780198736912-chapter-4.pdf},
}

@article{HACestimator,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/2938229},
 abstract = {This paper is concerned with the estimation of covariance matrices in the presence of heteroskedasticity and autocorrelation of unknown forms. Currently available estimators that are designed for this context depend upon the choice of a lag truncation parameter and a weighting scheme. Results in the literature provide a condition on the growth rate of the lag truncation parameter as T → ∞ that is sufficient for consistency. No results are available, however, regarding the choice of lag truncation parameter for a fixed sample size, regarding data-dependent automatic lag truncation parameters, or regarding the choice of weighting scheme. In consequence, available estimators are not entirely operational and the relative merits of the estimators are unknown. This paper addresses these problems. The asymptotic truncated mean squared errors of estimators in a given class are determined and compared. Asymptotically optimal kernel/weighting scheme and bandwidth/lag truncation parameters are obtained using an asymptotic truncated mean squared error criterion. Using these results, data-dependent automatic bandwidth/lag truncation parameters are introduced. The finite sample properties of the estimators are analyzed via Monte Carlo simulation.},
 author = {Donald W. K. Andrews},
 journal = {Econometrica},
 number = {3},
 pages = {817--858},
 publisher = {[Wiley, Econometric Society]},
 title = {Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation},
 urldate = {2023-11-22},
 volume = {59},
 year = {1991}
}

@Inbook{GLS,
author="Baltagi, Badi H.",
title="Generalized Least Squares",
bookTitle="Econometrics",
year="1998",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="237--251",
abstract="This chapter considers a more general variance covariance matrix for the disturbances. In other words, assumption 1 is relaxed so that u {\textasciitilde} (0,$\sigma$2$\Omega$) where $\Omega$ is a positive definite matrix of dimension (nxn). First $\Omega$ is assumed known and the BLUE for $\beta$ is derived. This estimator turns out to be different from {\$}{\$}{\{}{\backslash}hat {\backslash}beta {\_}{\{}ols{\}}{\}}{\$}{\$}, and is denoted by {\$}{\$}{\{}{\backslash}hat {\backslash}beta {\_}{\{}GLS{\}}{\}}{\$}{\$}, the generalized least squares estimator of $\beta$. Therefore, we study the properties of {\$}{\$}{\{}{\backslash}hat {\backslash}beta {\_}{\{}ols{\}}{\}}{\$}{\$}under this non-spherical form of the disturbances. Section 9.3 studies some special structures of $\Omega$ and derive the corresponding BLUE for $\beta$. Section 9.4 introduces normality and derives the maximum likelihood estimator. Sections 9.5 and 9.6 study the way in which test of hypothesis and prediction get affected by this general variance-covariance assumption on the disturbances. Section 9.7 studies the properties of this BLUE for $\beta$ when $\Omega$ is unknown, and is replaced by a consistent estimator. Section 9.8 studies what happens to the W, LR and LM statistics when u {\textasciitilde} N(0,$\sigma$2$\Omega$).",
isbn="978-3-662-00516-3",
doi="10.1007/978-3-662-00516-3_9",
url="https://doi.org/10.1007/978-3-662-00516-3_9"
}

@article{endogeneity,
author = {Aaron D. Hill and Scott G. Johnson and Lindsey M. Greco and Ernest H. O’Boyle and Sheryl L. Walter},
title ={Endogeneity: A Review and Agenda for the Methodology-Practice Divide Affecting Micro and Macro Research},

journal = {Journal of Management},
volume = {47},
number = {1},
pages = {105-143},
year = {2021},
doi = {10.1177/0149206320960533},

URL = { 
    
        https://doi.org/10.1177/0149206320960533
    
    

},
eprint = { 
    
        https://doi.org/10.1177/0149206320960533
    
    

}
,
    abstract = { An expanding number of methodological resources, reviews, and commentaries both highlight endogeneity as a threat to causal claims in management research and note that practices for addressing endogeneity in empirical work frequently diverge from the recommendations of the methodological literature. We aim to bridge this divergence, helping both macro and micro researchers understand fundamental endogeneity concepts by: (1) defining a typology of four distinct causes of endogeneity, (2) summarizing endogeneity causes and methods used in management research, (3) organizing the expansive methodological literature by matching the various methods to address endogeneity to the appropriate resources, and (4) setting an agenda for future scholarship by recommending practices for researchers and gatekeepers about identifying, discussing, and reporting evidence related to endogeneity. The resulting review builds literacy about endogeneity and ways to address it so that scholars and reviewers can better produce and evaluate research. It also facilitates communication about the topic so that both micro- and macro-oriented researchers can understand, evaluate, and implement methods across disciplines. }
}

@Inbook{DGP,
author="Aoki, Masanao",
title="Data Generating Processes",
bookTitle="State Space Modeling of Time Series",
year="1990",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="8--20",
abstract="Before we attempt to build models for some data series, we need to describe the scope of coverage, i.e., the class of data generating processes for which we design model-building algorithms. First, we assume that data are generated by linear processes. Second, throughout most of the book, we further assume that the processes are at least covariance (or weakly) stationary. We assume, that is, that the mean of the process is a constant not varying with time, and that the covariance matrices are functions of the differences of the two time instants and not of these two instants themselves. Later, when we discuss series with apparent trends, we drop this constant-mean assumption. Third, the spectral density matrix of the processes are rational---i.e., the elements of the matrix are ratios of finite order polynomials. This last assumption means that we can use a finite number of parameters to describe the process, such as finite-order ARMA processes or finite-dimensional state space models which are discussed in Chapter 4.",
isbn="978-3-642-75883-6",
doi="10.1007/978-3-642-75883-6_3",
url="https://doi.org/10.1007/978-3-642-75883-6_3"
}


@article{OVB,
author = {John R. Busenbark and Hyunjung (Elle) Yoon and Daniel L. Gamache and Michael C. Withers},
title ={Omitted Variable Bias: Examining Management Research With the Impact Threshold of a Confounding Variable (ITCV)},

journal = {Journal of Management},
volume = {48},
number = {1},
pages = {17-48},
year = {2022},
doi = {10.1177/01492063211006458},

URL = { 
    
        https://doi.org/10.1177/01492063211006458
    
    

},
eprint = { 
    
        https://doi.org/10.1177/01492063211006458
    
    

}
,
    abstract = { Management research increasingly recognizes omitted variables as a primary source of endogeneity that can induce bias in empirical estimation. Methodological scholarship on the topic overwhelmingly advocates for empirical researchers to employ two-stage instrumental variable modeling, a recommendation we approach with trepidation given the challenges associated with this analytic procedure. Over the course of two studies, we leverage a statistical technique called the impact threshold of a confounding variable (ITCV) to better conceptualize what types of omitted variables might actually bias causal inference and whether they have appeared to do so in published management research. In Study 1, we apply the ITCV to published studies and find that a majority of the causal inference is unlikely biased from omitted variables. In Study 2, we respecify an influential simulation on endogeneity and determine that only the most pervasive omitted variables appear to substantively impact causal inference. Our simulation also reveals that only the strongest instruments (perhaps unrealistically strong) attenuate bias in meaningful ways. Taken together, we offer guidelines for how scholars can conceptualize omitted variables in their research, provide a practical approach that balances the tradeoffs associated with instrumental variable models, and comprehensively describe how to implement the ITCV technique. }
}

@article{IVREG,
title = {Instrument strength in IV estimation and inference: A guide to theory and practice},
journal = {Journal of Econometrics},
volume = {235},
number = {2},
pages = {1625-1653},
year = {2023},
issn = {0304-4076},
doi = {https://doi.org/10.1016/j.jeconom.2022.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304407623000222},
author = {Michael Keane and Timothy Neal},
keywords = {Instrumental variables, Weak instruments, 2SLS, Endogeneity, F-test, Size distortion, Anderson–Rubin test, Likelihood ratio test, LIML, GMM, Fuller, JIVE},
abstract = {Two stage least squares (2SLS) has poor properties if instruments are exogenous but weak. But how strong do instruments need to be for 2SLS estimates and test statistics to exhibit acceptable properties? A common standard is that first-stage F≥10. This is adequate to ensure two-tailed t-tests have modest size distortions. But other problems persist: In particular, we show 2SLS standard errors are artificially small in samples where the estimate is most contaminated by the OLS bias. Hence, if the bias is positive, the t-test has little power to detect true negative effects, and inflated power to find positive effects. This phenomenon, which we call a “power asymmetry,” persists even if first-stage F is in the thousands. Robust tests like Anderson–Rubin perform better, and should be used in lieu of the t-test even with strong instruments. We also show how 2SLS test statistics typically suffer from very low power if first-stage F is only 10, leading us to suggest a higher standard of instrument strength in empirical practice.}
}

@Inbook{2SLS,
author="Mariano, Roberto S.",
editor="Lovric, Miodrag",
title="Two-Stage Least Squares",
bookTitle="International Encyclopedia of Statistical Science",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1616--1618",
isbn="978-3-642-04898-2",
doi="10.1007/978-3-642-04898-2_599",
url="https://doi.org/10.1007/978-3-642-04898-2_599"
}

